{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f588659",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(this will take a few minutes to install all the dependences!)\n",
    "!pip install deeplabcut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a42b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use TensorFlow 1.x:\n",
    "%tensorflow_version 1.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff82016",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, let's link to your GoogleDrive. Run this cell and follow the authorization instructions:\n",
    "#(We recommend putting a copy of the github repo in your google drive if you are using the demo \"examples\")\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0c6efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup your project variables:\n",
    "# PLEASE EDIT THESE:\n",
    "  \n",
    "ProjectFolderName = 'mired_rata-ainhoa-2021-11-17' #cambiar por nombre de la carpeta\n",
    "VideoType = 'mp4' \n",
    "\n",
    "#don't edit these:\n",
    "videofile_path = ['/content/drive/My Drive/'+ProjectFolderName+'/videos/'] #Enter the list of videos or folder to analyze.\n",
    "videofile_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee3d193",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GUIs don't work on the cloud, so label your data locally on your computer! This will suppress the GUI support\n",
    "import os\n",
    "os.environ[\"DLClight\"]=\"True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e5078d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeplabcut\n",
    "deeplabcut.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4ca48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This creates a path variable that links to your google drive copy\n",
    "#No need to edit this, as you set it up before: \n",
    "path_config_file = '/content/drive/My Drive/'+ProjectFolderName+'/config.yaml'\n",
    "path_config_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48debae",
   "metadata": {},
   "source": [
    "# CREATING A TRAINING DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf6eefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the docstring for full options you can do!\n",
    "#num_shuffles --> If the user wishes to benchmark the performance of the DeepLabCut, they can create multiple\n",
    "#training datasets by specifying an integer value to the num_shuffles.\n",
    "deeplabcut.create_training_dataset(path_config_file, net_type='resnet_50', augmenter_type='imgaug', num_shuffles=1)\n",
    "#cada it de creation_dataset crea un archivo .mat y .pickle (contiene meta info).\n",
    "#se crean tambien subdirectorios train y test con pose_cfg.yaml (editar el de train andtes de empezar funcion training)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232ed690",
   "metadata": {},
   "source": [
    "# TRAINING THE NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c9049e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tiempo estimado:  NVIDIA GeForce GTX 1080 Ti GPU, it takes ≈ 6 hrs to train the network for at least 200,000 iterations \n",
    "#let's also change the display and save_iters just in case Colab takes away the GPU... \n",
    "#if that happens, you can reload from a saved point. Typically, you want to train to 200,000 + iterations.\n",
    "\n",
    "#shuffle: Integer value specifying the shuffle index to select for training. Default is set to 1\n",
    "#trainingsetindex: Integer specifying which Training set Fraction to use. By default the first (note that Training Fraction is a list in config.yaml).\n",
    "#gputouse: Natural number indicating the number of your GPU (see number in nvidia-smi). If you do not have a GPU put None\n",
    "#max_snapshots_to_keep: This sets how many snapshots are kept, i.e. states of the trained network. Every sav\u0002ing iteration a snapshot is stored, however only the last max_snapshots_to_keep many are kept! If you change this to None, then all are kept.\n",
    "#autotune: property of TensorFlow, tested to be faster if set to ’False’ (default)\n",
    "#displayiters: this variable is actually set in pose_config.yaml. However, you can overwrite it with this. If None, the value from pose_config.yaml is used, otherwise it is overwritten! Default: None\n",
    "#saveiters: this variable is set in pose_config.yaml. However, you can overwrite it with this. If None, the value from there is used, otherwise it is overwritten! Default: None\n",
    "\n",
    "deeplabcut.train_network(path_config_file, shuffle=1, displayiters=100,saveiters=500)\n",
    "#this will run until you stop it (CTRL+C), or hit \"STOP\" icon, or when it hits the end (default, 1.03M iterations). \n",
    "#Whichever you chose, you will see what looks like an error message, but it's not an error - don't worry....\n",
    "#weights de TF en subdirect \\models\\pre-trained\\Pose_Estimation_Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b3e357",
   "metadata": {},
   "source": [
    "If the user wishes to restart the training at a specific\n",
    "checkpoint they can specify the full path of the checkpoint to the variable ‘init_weights’ in the pose_cfg.yaml file\n",
    "under the ‘train’ subdirectory "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169d4fe6",
   "metadata": {},
   "source": [
    "# EVALUATING THE NETWORK\n",
    "This funtion evaluates a trained model for a specific shuffle/shuffles at a particular state or all the states on the data set (images) and stores the results as .csv file in a subdirectory under evaluation-results\n",
    "The plots can be customized by editing the config.yaml file (i.e. the colormap, scale, marker size (dotsize), and\n",
    "transparency of labels (alphavalue) can be modified).\n",
    "Note that by default the human labels are\n",
    "plotted as plus (‘+’), DeepLabCut’s predictions either as ‘.’ (for confident predictions with likelihood > p-cutoff) and\n",
    "’x’ for (likelihood <= p-cutoff)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44315080",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "deeplabcut.evaluate_network(path_config_file,shuffle=[1],plotting=True)\n",
    "\n",
    "# Here you want to see a low pixel error! Of course, it can only be as good as the labeler, \n",
    "#so be sure your labels are good! (And you have trained enough ;)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345f43a4",
   "metadata": {},
   "source": [
    "# # OPTIONAL REFINEMENT STEP (OUTSIDE COLAB)\n",
    "## There is an optional refinement step you can do outside of Colab:\n",
    "If your pixel errors are not low enough, please check out the protocol guide on how to refine your network!\n",
    "You will need to adjust the labels **outside of Colab!** We recommend coming back to train and analyze videos... \n",
    "Please see the repo and protocol instructions on how to refine your data!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc06d1d",
   "metadata": {},
   "source": [
    "# VIDEO ANALYSIS\n",
    "The user needs to first choose a checkpoint with the best\n",
    "evaluation results for analyzing the videos. In this case, the user can enter the corresponding index of the checkpoint\n",
    "to the variable snapshotindex in the config.yaml file. By default, the most recent checkpoint (i.e. last) is used for\n",
    "analyzing the video. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e865dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.analyze_videos(path_config_file,videofile_path, videotype=VideoType, shuffle=1, save_as_csv=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b0ffbd",
   "metadata": {},
   "source": [
    "The labels are stored in a MultiIndex Pandas Array ([41], http://pandas.pydata.org), which contains the name\n",
    "of the network, body part name, (x, y) label position in pixels, and the likelihood for each frame per body part.\n",
    " if the flag save_as_csv is set to True, the data can also be exported in comma-separated values format\n",
    "(.csv), which in turn can be imported in many programs, such as MATLAB, R, Prism, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b10a0a9",
   "metadata": {},
   "source": [
    "# CREATE LABELED VIDEO\n",
    "This funtion is for visualiztion purpose and can be used to create a video in .mp4 format with labels predicted by the network. This video is saved in the same directory where the original video resides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673ea3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#editar dotsize label en config.yaml\n",
    "deeplabcut.create_labeled_video(path_config_file,videofile_path, videotype=VideoType)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
